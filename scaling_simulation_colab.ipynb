{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d464ce32",
   "metadata": {},
   "source": [
    "# Resource Scaling Simulation — Horizontal vs Vertical (Colab-ready)\n",
    "\n",
    "**What this notebook contains**\n",
    "- A runnable Python simulation that demonstrates **horizontal scaling** (threads) vs **vertical scaling** (processes).\n",
    "- Ready-to-run in Google Colab: paste the notebook file into Colab or upload it.\n",
    "- A short **Viva questions & model answers** section you can use during your practical.\n",
    "\n",
    "**How to run**\n",
    "1. Open [Google Colab](https://colab.research.google.com).\n",
    "2. Upload this notebook (File → Upload notebook) or use **File → Open notebook → Upload**.\n",
    "3. Run the single code cell. It is self-contained and executes the experiments automatically.\n",
    "\n",
    "**Important notes for Colab**\n",
    "- The notebook uses `multiprocessing`. Colab runs in a container environment where multiprocessing works, but if a process spawn problem occurs, re-run the cell.\n",
    "- Adjust the `threads`, `thread_iters`, `processes`, and `proc_base_iters` variables to change experiment intensity.\n",
    "- If you want live charts or longer runs, ask me and I'll add `psutil` and plotting cells.\n",
    "\n",
    "---\n",
    "\n",
    "## Viva Questions (short answers)\n",
    "1. **What is horizontal scaling?**  \n",
    "   Adding more instances (scale-out) to distribute load.\n",
    "\n",
    "2. **What is vertical scaling?**  \n",
    "   Increasing resources (CPU, RAM) of a single instance (scale-up).\n",
    "\n",
    "3. **Which Python primitives are used?**  \n",
    "   `threading.Thread` for horizontal, `multiprocessing.Process` for vertical.\n",
    "\n",
    "4. **What is GIL?**  \n",
    "   Global Interpreter Lock in CPython that limits concurrent execution of Python bytecode in threads.\n",
    "\n",
    "5. **Why use processes for CPU-bound tasks?**  \n",
    "   Processes bypass the GIL and can run on separate CPU cores.\n",
    "\n",
    "(There are more viva Qs in the notebook's code comments; review them before the exam.)\n",
    "\n",
    "*Generated on 2025-11-25 17:59:16*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58939622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab-ready: Horizontal vs Vertical Scaling Simulation\n",
    "# Run this single cell in Colab to execute the experiments.\n",
    "# No external pip installs needed.\n",
    "\n",
    "import time\n",
    "import threading\n",
    "import multiprocessing\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------- Worker functions (simulate CPU-bound work) ----------\n",
    "def cpu_workload(iterations, label=None):\n",
    "    \"\"\"\n",
    "    CPU-bound work: calculates many squares to consume CPU.\n",
    "    iterations: how many loop iterations (larger => more CPU per worker)\n",
    "    \"\"\"\n",
    "    if label:\n",
    "        print(f\"[{datetime.now().strftime('%H:%M:%S')}] {label} started (iter={iterations})\")\n",
    "    s = 0\n",
    "    for i in range(iterations):\n",
    "        s += (i * i) % (i + 1 if i else 1)\n",
    "        # small conditional to avoid heavy I/O\n",
    "        if i % (iterations // 5 + 1) == 0:\n",
    "            pass\n",
    "    if label:\n",
    "        print(f\"[{datetime.now().strftime('%H:%M:%S')}] {label} finished\")\n",
    "    return s\n",
    "\n",
    "# ---------- Horizontal scaling (threads) ----------\n",
    "def horizontal_scaling(num_instances=4, iterations_per_instance=250_000):\n",
    "    \"\"\"\n",
    "    Simulate horizontal scaling by spawning multiple threads (each thread = instance).\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Horizontal Scaling (threads) ===\")\n",
    "    print(f\"Spawning {num_instances} thread-instances, each with {iterations_per_instance} iterations.\")\n",
    "    threads = []\n",
    "    start = time.time()\n",
    "    for i in range(num_instances):\n",
    "        t = threading.Thread(\n",
    "            target=cpu_workload,\n",
    "            args=(iterations_per_instance, f\"thread-instance-{i+1}\"),\n",
    "            daemon=False\n",
    "        )\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "        time.sleep(0.05)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Horizontal scaling (threads) finished in {elapsed:.2f} seconds.\\n\")\n",
    "    return elapsed\n",
    "\n",
    "# ---------- Vertical scaling (processes) ----------\n",
    "def vertical_scaling(num_cores=2, iterations_base=400_000):\n",
    "    \"\"\"\n",
    "    Simulate vertical scaling by using processes (each process simulates using a CPU core).\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Vertical Scaling (processes) ===\")\n",
    "    print(f\"Spawning {num_cores} processes (simulated cores).\")\n",
    "    procs = []\n",
    "    manager = multiprocessing.Manager()\n",
    "    return_dict = manager.dict()\n",
    "\n",
    "    def proc_target(proc_id, iterations, ret_dict):\n",
    "        res = cpu_workload(iterations, label=f\"proc-core-{proc_id}\")\n",
    "        ret_dict[proc_id] = res\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(num_cores):\n",
    "        iterations = iterations_base * (1 + i//1)\n",
    "        p = multiprocessing.Process(target=proc_target, args=(i+1, iterations, return_dict))\n",
    "        procs.append(p)\n",
    "        p.start()\n",
    "        time.sleep(0.05)\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Vertical scaling (processes) finished in {elapsed:.2f} seconds.\")\n",
    "    print(f\"Returned results keys (should equal cores): {list(return_dict.keys())}\\n\")\n",
    "    return elapsed\n",
    "\n",
    "# ---------- Combined experiment runner ----------\n",
    "def run_experiments():\n",
    "    print(\"Resource scaling demo - Colab friendly\")\n",
    "    print(f\"Python PID: {os.getpid()}, CPU count (os): {os.cpu_count()}\\n\")\n",
    "    # Adjustable parameters\n",
    "    threads = 4\n",
    "    thread_iters = 250_000\n",
    "    processes = 2\n",
    "    proc_base_iters = 400_000\n",
    "\n",
    "    print(\">> Running horizontal scaling experiment (threads)...\")\n",
    "    t_h = horizontal_scaling(num_instances=threads, iterations_per_instance=thread_iters)\n",
    "\n",
    "    print(\">> Running vertical scaling experiment (processes)...\")\n",
    "    t_v = vertical_scaling(num_cores=processes, iterations_base=proc_base_iters)\n",
    "\n",
    "    print(\"Summary (lower time = more parallel available for this environment):\")\n",
    "    print(f\" - Horizontal (threads) time: {t_h:.2f}s\")\n",
    "    print(f\" - Vertical   (processes) time: {t_v:.2f}s\")\n",
    "    if t_h < t_v:\n",
    "        print(\"Interpretation hint: In this environment, threads finished faster for these parameters.\")\n",
    "    else:\n",
    "        print(\"Interpretation hint: In this environment, processes finished faster for these parameters.\")\n",
    "    print(\"\\nNote: Real cloud scaling behavior depends on actual CPU core count, IO, and scheduler.\\n\")\n",
    "\n",
    "# Run experiments when this cell is executed\n",
    "run_experiments()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
